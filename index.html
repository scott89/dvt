<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>reveal.js â€“ The HTML Presentation Framework</title>

		<meta name="description" content="Deep Learning, Vision, and Others">
		<meta name="author" content="Lijun Wang">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/white.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
                                <section data-transition="zoom" data-background="fig/deep_dream.jpg" >
                                        <br><br>
					<h1>Deep Learning, Vision, and Others</h1>
                                        <br>
                                        <h3 background-color:rgba(255,255,255,0.8)>
                                        <!--  <font color="red">Created by <a href="https://scholar.google.com/citations?user=EfTwkXMolscC&hl=en">Lijun Wang</a></font> -->
                                         Created by <a href="https://scholar.google.com/citations?user=EfTwkXMolscC&hl=en">Lijun Wang</a> 
					</h3>
				</section>
                                <section>
                                        <section>
                                                <h2> What is Deep Networks?</h2>
                                                <ul>
                                                        <li><p class="fragment"> What is neural networks (CNNs, RNNs, SAE, DBN)?</p></li>
                                                        <li><p class="fragment"> How to distinguish deep and shallow models?</p></li>
                                                </ul>
                                                <p class="fragment"> Are they deep or shallow models: <span class=fragment>SVMs, </span>
                                                <span class=fragment>three-layer CNNs, </span> 
                                                <span class=fragment>20-layer CNNs?</span></p></li>
                                        </section>
                                        <section>
                                                <h2>The Universal Appriximator Theorem [1]</h2>
                                                <blockquote>A neural network with at least one hidden layer can represent any function to an arbitary degree of
                                                accuracy so long as its hidden layer is permitted to have enough units.</blockquote>
                                                <small>[1] Hornik, Kurt, Stinchcombe, Maxwell, and White, Halbert. Multilayer feedforward networks are universal
                                                approximators. Neural Networks, 1989</small>
                                        </section>
                                        <section>
                                                <h2>So What?</h2>
                                                <ul>
                                                    <li>Shallow models: overfitting, reducing model complexity, adding regularization. </li> 
                                                    <li>Deep models: underfitting, increasing model complexity, optimization, computation resource</li>



                                                </ul>
                                                <img width=50% data-src="fig/deep_shallow.png">
                                        </section>
                                </section>
                                <section>
                                        <h2>Overview</h2><br>
                                        <ul>
                                                <li><h3>Image Classification</h3></li>
                                                <li><h3>Object Detection</h3></li>
                                                <li><h3>Dense Prediction</h3></li>
                                                <li><h3>Sequance Modeling</h3></li>
                                        </ul>
                                </section>
                                <section data-transition="zoom">
                                        <h2>Image Classification</h2>
                                        </br>
                                        <ul>
                                                <li><h3>Alex Net</h3></li>
                                                <li><h3>VGG Net</h3></li>
                                                <li><h3>GoogLe Net</h3></li>
                                                <li><h3>Deep Residual Net</h3></li>
                                        </ul>
                                        
                                </section>
                                <section>
                                        <section>
                                                <h2> Alex Net (2012, Top5: 16.4%)</h2>
                                                <p>5 Conv + 3 fully connected</p>
                                                <img width=88% data-src="fig/alex.png">
                                                <img width=88% data-src="fig/alex_res.png">
                                                
                                        </section>
                                        <section>
                                                <h2>New Technologies (Tricks)</h2>
                                                <ul>
                                                        <li>ReLU non-linear units </li>
                                                        <li>Dropout</li>
                                                        <li>Local response normalization</li>
                                                        <li>Data augmentation</li>
                                                        <li class="fragment highlight-red">1.2 million training + 50k validation</li>
                                                        <li class="fragment highlight-red">GPU training</li>
                                                </ul>
                                                
                                        </section>

                                </section>
                                <section>
                                        <section>
                                                <h2> VGG Net (2014, Top5: 7.32%)
                                                <img width = 70% data-src="fig/vgg.png">
                                        </section>
                                        <section> 
                                                <h2>New Knowledge (Feature)</h2>
                                                <ul>
                                                        <li class=fragment> Increasing depth with small (3x3) convolution filters.</li>
                                                        <ul>
                                                                <li class=fragment> A stack of two 3x3 conv layers has an effecitve receptive field of 5x5,</li>
                                                                <li class=fragment> but incorparates one additional non-linear layers,</li>
                                                                <li class=fragment> and reduces parameters</li>
                                                        </ul>
                                                        <li class=fragment> Preserve time complextiy per layer.</li>
                                                        <ul>
                                                                <li class=fragment> Layers with same output feature map size have the same number of filters.</li>
                                                                <li class=fragment> If the feature map size is halved, the number of filters is doubled.</li>
                                                        </ul>
                                                </ul>

                                        </section>
                                </section>
                                <section>
                                        <section>
                                                <h2>GoogLeNet (2014, Top5: 6.67%)</h2>
                                                <img width=98% data-src="fig/googlenet.png">
                                        </section>
                                        <section>
                                                <h2>Architecture Designs </h2>
                                                <ul>
                                                        <li class=fragment> <p>Global average pooling[2] before fully connected layers.</p></li>
                                                        <li class=fragment> <p>Multiple loss layers to enforce gradient back-propagation and encourage discrimination in lower layers.</p></li>
                                                        <li class=fragment> <p>Inceptions</p></li>
                                                </ul> <br><br><br><br><br>
                                                <small>[2] Min Lin el al. Network in network. CoRR, abs/1312.4400, 2013.</small>
                                        </section>
                                        <section>
                                                <h2> Inception </h2>
                                                <ul>
                                                        <li> Increasing feature map channels without blowing-up computational complexity.
                                                        <li> Processing signals at different scales and aggregating for abstraction. 
                                                </ul><br><br>
                                                <img width=90% data-src="fig/inception.png">
                                        </section>
                                </section>
                                <section>
                                        <section>
                                                <h2> Deep Resedual Network <small>(2015, Top5: 3.57% human-level: 5.1%)</small></h2>
                                                <blockquote>Degradation problem: with network depth increasing, accuracy gets asturated and then degrades. </blockquote>
                                                <img width=90% data-src="fig/degradation.png">
                                        </section>
                                        <section>
                                                <h2>Residual Learning </h2>
                                                <ul>
                                                        <li><p>Fit a residual mapping $\mathcal{F}(\mathbf{x}):=\mathcal{H}(\mathbf{x})-\mathbf{x}$, 
                                                        rather than fitting the original mapping $\mathcal{H}(\mathcal{x})$</p></li>
                                                        <li>It is easier to optimize the residual mapping (Considering an identity mapping as optimal).</li>
                                                </ul><br>
                                                <img width = 60% data-src="fig/res_learn.png">
                                        </section>
                                        <section>
                                                <h2>Network Architecture</h2>
                                                <img width=100% data-src="fig/res.png">
                                        </section>
                                        <section>
                                                <h2>Building Blocks</h2>
                                                <p>Identity mapping by short connect.</p>
                                                <img width=90% data-src="fig/shortconnect.png">
                                                <h3>         Naive     v.s.    Bottleneck  </3>
                                        </section>
                                        <section>
                                                <h2>Deep Residual Net Address Degradation</h2>
                                                <img width=90% data-src="fig/res_res.png">
                                        </section>
                                </section>
                                <section data-transition="zoom">
                                        <h2>Object Detection</h2>
                                        </br>
                                        <ul>
                                                <li><h3>R-CNN</h3></li>
                                                <li><h3>Fast R-CNN</h3></li>
                                                <li><h3>Faster R-CNN</h3></li>
                                                <li><h3>YOlO</h3></li>
                                        </ul>
                                </section>
                                <section>
                                        <section>
                                                <h2>R-CNN: Regions with CNN Features<h2>
                                                <img width=90% data-src="fig/rcnn.jpg">
                                        </section>
                                        <section>
                                                <h2>Pros and Cons</h2>
                                                <ul>
                                                        <li class="fragment">The first detector eploring deep CNN features with excellent performance.</li>
                                                        <li class="fragment">Training is a multi-stage pipeline</li>
                                                        <li class="fragment">Training is expensive in sapce and time</li>
                                                        <li class="fragment">Object detection is slow (47s/f)</li>
                                                </ul>
                                        </section>

                                </section>
                                <section>
                                        <section>
                                                <h2>Fast R-CNN</h2>
                                                <img width=90% data-src="fig/fast_rcnn">
                                        </section>
                                        <section>
                                                <h2>Key Features</h2>
                                                <ol>
                                                        <li class="fragment">RoI pooling layer: extracts fixed length feature for each region proposal.</li>
                                                        <li class="fragment">Multitask Learning: $L(p,u,t^u,v)=L_{cls}(p,u) + \lambda L_{loc}(t^u,v)$</li>
                                                </ol>
                                                </br><br><br>
                                                <ul>
                                                        <li class="fragment">Training is single-stage and update all network layers.</li>
                                                        <li class="fragment">No disk storage is required for feature caching.</li>
                                                </ul>
                                        </section>
                                </section>
                                <section>
                                        <section>
                                                <h2>Faster R-CNN</h2>
                                                <img width=40% data-src="fig/faster_rcnn.png">
                                                <ul>
                                                        <li>Feature Net + RPN + Fast R-CNN </li>
                                                        <li>Share deep features between object proposal and detection.</li>
                                        </section>
                                        <section>
                                                <h2>Region Proposal Net (RPN)</h2>
                                                <div>
                                                        <div class="left" style="float: left; width: 50%">
                                                                <ul>
                                                                        <li class="fragment">Slide a 3x3 filter on the convolution feature map to obtain a feature vector.</li>
                                                                        <li class="fragment">Two sibling layers: box regression (reg) and classificaion (cls)</li>
                                                                        <li class="fragment">For each window center, reg outputs 4k coordinates, cls outputs 2k class score with respect to k anchors.</li>
                                                                </ul>
                                                        </div>
                                                        <div class="right" style="float: right; width: 50%">
                                                        <br><br>
                                                                <img width=100% data-src="fig/rpn.png">
                                                        </div>
                                                </div>

                                        </section>
                                        <section>
                                                <h2>Training RPN, Fast R-CNN, and Feature Net</h2>
                                                <div>
                                                        <div class="left" style="float: left; width: 50%">
                                                                <ul>
                                                                        <li>Alternating training.</li>
                                                                        <li>Approximate joint training.</li>
                                                                        <li>Non-approximate joint training.</li>
                                                                </ul>
                                                        </div>
                                                        <div class="right" style="float: right; width: 50%">
                                                                <img width=100% data-src="fig/faster_rcnn.png">
                                                        </div>
                                                </div>

                                        </section>
                                </section>
                                <section>
                                        <section>
                                                <h2>YOLO: You Only Look Once</h2>
                                                <ul>
                                                        <li class="fragment"> Divie image into a 7x7 grid, each grid cell is responsible to detect the object within the grid.</li>
                                                        <li class="fragment"> Each cell predicts 2 bounding box and 20 class probabilities</li>
                                                        <li class="fragment"> Each bounding box includes 5 predictions: 4 relative coordinates and 1 object confidence.</li>
                                                        <li class="fragment"> Totally 7x7(2x5+20)=7x7x30 output unites.</li>
                                                </ul>
                                                <img width=50% data-src="fig/yolo.png">
                                        </section>

                                        <section>
                                                <h2>Detector Design</h2>
                                                <ul>
                                                        <li class="fragment">First 20 layers are pretrained on image classification.</li>
                                                        <li class="fragment">Increase input resolution from 224x224 to 448x448.</li>
                                                        <li class="fragment">In finetuning, each object only update 1 responsive predictior among 7x7x2 predictors.</li>
                                                </ul>
                                                <img width = 80% data-src="fig/yolo_net.png">
                                        </section>
                                        <section>
                                                <h2>Performance Comparison</h2>
                                                <img width=70% data-src="fig/pascal_2007.png">
                                        </section>
                                </section>
                                <section>
                                        <h2>Dense Prediction</h2>
                                        <ul>
                                                <li>to be continued ...</li>
                                        </ul>
                                </section>
                                <section>
                                        <h3>How people viewed networks 20 years ago</h3>
                                        <blockquote>
                                                "In spite of the seemly different underlying principles, most of the well known neural network models are implicitly equivalent or similar to classical statistical pattern recognition methods" Jain TPAMI 2000.
                                        </blockquote>
                                        <blockquote>
                                                "Neural networks are statistics for amateursâ€¦ Most neural networks conceal the statistics from the user" Anderson, 1990. 
                                        </blockquote>
                                </section>
                                <section>
                                        <h2>What's next?</h2>
                                        <ul>
                                                <li class="fragment">Simply using deep learning for vision problem is not sufficient to get our papers accepted. We are entering the post-deep-learning era. </li>
                                                <li class="fragment">We should follow most recent pregress of deep learning by reading more papers and build solid foundation on machine learning as well.</li>
                                        </ul>
                                </section>


			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: false,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true },
                                        { src: 'plugin/math/math.js', async: true}
				]
			});

		</script>

	</body>
</html>
